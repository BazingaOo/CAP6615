{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAP 6615 Neural Networks Programming Assignment 2 – Multi-Layer Neural Network\n",
    "\n",
    "### Keyuan Lu, Wenxuan Bao, Yiming Xu, Yufan Chen, Yue Bai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Design and build a dataset for RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "price=pd.read_csv('HistoricalPrices.csv')\n",
    "pe=pd.read_csv('ie_data_PE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_PE</th>\n",
       "      <th>PE_CAPE</th>\n",
       "      <th>TR CAPE</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1978.01</td>\n",
       "      <td>9.24</td>\n",
       "      <td>11.12</td>\n",
       "      <td>9.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978.02</td>\n",
       "      <td>9.05</td>\n",
       "      <td>10.89</td>\n",
       "      <td>9.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1978.03</td>\n",
       "      <td>8.95</td>\n",
       "      <td>10.79</td>\n",
       "      <td>9.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1978.04</td>\n",
       "      <td>9.26</td>\n",
       "      <td>11.18</td>\n",
       "      <td>9.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1978.05</td>\n",
       "      <td>9.63</td>\n",
       "      <td>11.64</td>\n",
       "      <td>8.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>2020.08</td>\n",
       "      <td>31.15</td>\n",
       "      <td>34.16</td>\n",
       "      <td>4.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>2020.09</td>\n",
       "      <td>30.83</td>\n",
       "      <td>33.81</td>\n",
       "      <td>4.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2020.10</td>\n",
       "      <td>31.28</td>\n",
       "      <td>34.30</td>\n",
       "      <td>4.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2020.11</td>\n",
       "      <td>32.47</td>\n",
       "      <td>35.61</td>\n",
       "      <td>3.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2020.12</td>\n",
       "      <td>33.77</td>\n",
       "      <td>37.03</td>\n",
       "      <td>3.77%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_PE  PE_CAPE  TR CAPE  Yield\n",
       "0    1978.01     9.24    11.12  9.11%\n",
       "1    1978.02     9.05    10.89  9.31%\n",
       "2    1978.03     8.95    10.79  9.47%\n",
       "3    1978.04     9.26    11.18  9.03%\n",
       "4    1978.05     9.63    11.64  8.49%\n",
       "..       ...      ...      ...    ...\n",
       "511  2020.08    31.15    34.16  4.32%\n",
       "512  2020.09    30.83    33.81  4.33%\n",
       "513  2020.10    31.28    34.30  4.17%\n",
       "514  2020.11    32.47    35.61  3.96%\n",
       "515  2020.12    33.77    37.03  3.77%\n",
       "\n",
       "[516 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe=pe.rename({'Date':'Date_PE'},axis=1)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-4c043bae6b4b>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price['Date_PE'][i]=year+month*0.01\n"
     ]
    }
   ],
   "source": [
    "price['Date_PE']=0.0\n",
    "for i in range(price.shape[0]):\n",
    "    month=int(price['Date'][i][0:2])\n",
    "    year=int(price['Date'][i][-2:])\n",
    "    if year>50:\n",
    "        year=year+1900\n",
    "    else:\n",
    "        year=year+2000\n",
    "    price['Date_PE'][i]=year+month*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.merge(price,pe,how='left',on='Date_PE')\n",
    "data.to_csv('Price_PE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Date', ' Open', ' High', ' Low', ' Close'\n",
    "raw_data_price = genfromtxt('Price_PE.csv', delimiter=',',dtype=str)\n",
    "raw_data_price = raw_data_price[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '01/03/78', '93.82', ..., '9.24', '11.12', '9.11%'],\n",
       "       ['1', '01/04/78', '93.52', ..., '9.24', '11.12', '9.11%'],\n",
       "       ['2', '01/05/78', '92.74', ..., '9.24', '11.12', '9.11%'],\n",
       "       ...,\n",
       "       ['10841', '12/29/20', '3750.01', ..., '33.77', '37.03', '3.77%'],\n",
       "       ['10842', '12/30/20', '3736.19', ..., '33.77', '37.03', '3.77%'],\n",
       "       ['10843', '12/31/20', '3733.27', ..., '33.77', '37.03', '3.77%']],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "raw_data_price = np.flip(raw_data_price,0)\n",
    "count = 0\n",
    "for x in raw_data_price:\n",
    "    x[0] = str(count)\n",
    "    count += 1\n",
    "raw_data_price\n",
    "#Index,Date, Open, High, Low, Close,Date_PE,PE_CAPE,TR CAPE,Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['93.82', '9.24'],\n",
       "       ['93.52', '9.24'],\n",
       "       ['92.74', '9.24'],\n",
       "       ...,\n",
       "       ['3727.04', '33.77'],\n",
       "       ['3732.04', '33.77'],\n",
       "       ['3756.07', '33.77']], dtype='<U8')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We are only using ClOSE price and Cyclicily adjusted PE-ratio as data frame\n",
    "training_set = raw_data_price[:,[5,7]]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data format setting\n",
    "#Input size is 5 because we are using a weeks data as data batch.\n",
    "INPUT_SIZE =5\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_SIZE = 1\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 180 timesteps and 1 output\n",
    "# we hold 176 data as training data, and 4 data points use for testing\n",
    "X_train = []\n",
    "y_train = []\n",
    "curWindowBeginning = 0\n",
    "curWindowEnd = 180\n",
    "curTrainSetEnd = curWindowBeginning+176\n",
    "for i in range(INPUT_SIZE, curTrainSetEnd):\n",
    "    X_train.append(training_set_scaled[i-INPUT_SIZE:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Design and develop RNN in Python, using libraries such as PyTorch (and, if necessary, Tensor Flow). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, i_size, h_size, n_layers, o_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=i_size,\n",
    "            hidden_size=h_size,\n",
    "            num_layers=n_layers\n",
    "        )\n",
    "        self.out = nn.Linear(h_size, o_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r_out, _ = self.rnn(x)\n",
    "        outs = self.out(r_out)\n",
    "\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE)\n",
    "#set the model to the device that we defined earlier (default is CPU)\n",
    "optimiser = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "hidden_state = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Train your RNN using time window 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE:  0.04459018260240555\n",
      "Epoch  1 MSE:  0.02656456269323826\n",
      "Epoch  2 MSE:  0.013705183751881123\n",
      "Epoch  3 MSE:  0.005406174808740616\n",
      "Epoch  4 MSE:  0.0011081787524744868\n",
      "Epoch  5 MSE:  0.00015474851534236223\n",
      "Epoch  6 MSE:  0.0015519496519118547\n",
      "Epoch  7 MSE:  0.0038238847628235817\n",
      "Epoch  8 MSE:  0.005562224425375462\n",
      "Epoch  9 MSE:  0.006138057913631201\n",
      "Epoch  10 MSE:  0.005636738613247871\n",
      "Epoch  11 MSE:  0.004464942030608654\n",
      "Epoch  12 MSE:  0.003064868040382862\n",
      "Epoch  13 MSE:  0.0017819084459915757\n",
      "Epoch  14 MSE:  0.0008250933024100959\n",
      "Epoch  15 MSE:  0.00027435601805336773\n",
      "Epoch  16 MSE:  0.00010848174861166626\n",
      "Epoch  17 MSE:  0.00023910505115054548\n",
      "Epoch  18 MSE:  0.0005437942454591393\n",
      "Epoch  19 MSE:  0.0008966567111201584\n",
      "Epoch  20 MSE:  0.0011946591548621655\n",
      "Epoch  21 MSE:  0.0013732727384194732\n",
      "Epoch  22 MSE:  0.0014088456518948078\n",
      "Epoch  23 MSE:  0.0013118047500029206\n",
      "Epoch  24 MSE:  0.0011156527325510979\n",
      "Epoch  25 MSE:  0.0008652919786982238\n",
      "Epoch  26 MSE:  0.0006067418144084513\n",
      "Epoch  27 MSE:  0.0003792540810536593\n",
      "Epoch  28 MSE:  0.00021015854144934565\n",
      "Epoch  29 MSE:  0.00011243568587815389\n",
      "Epoch  30 MSE:  8.483862620778382e-05\n",
      "Epoch  31 MSE:  0.00011423850810388103\n",
      "Epoch  32 MSE:  0.00017966657469514757\n",
      "Epoch  33 MSE:  0.0002572864468675107\n",
      "Epoch  34 MSE:  0.00032533128978684545\n",
      "Epoch  35 MSE:  0.00036802273825742304\n",
      "Epoch  36 MSE:  0.0003777444362640381\n",
      "Epoch  37 MSE:  0.0003551912377588451\n",
      "Epoch  38 MSE:  0.0003077546716667712\n",
      "Epoch  39 MSE:  0.0002467798185534775\n",
      "Epoch  40 MSE:  0.0001845031656557694\n",
      "Epoch  41 MSE:  0.0001313841057708487\n",
      "Epoch  42 MSE:  9.431404760107398e-05\n",
      "Epoch  43 MSE:  7.589191955048591e-05\n",
      "Epoch  44 MSE:  7.469535194104537e-05\n",
      "Epoch  45 MSE:  8.629348303657025e-05\n",
      "Epoch  46 MSE:  0.00010465858940733597\n",
      "Epoch  47 MSE:  0.00012362893903627992\n",
      "Epoch  48 MSE:  0.00013813235273119062\n",
      "Epoch  49 MSE:  0.00014498451491817832\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    inputs = Variable(torch.from_numpy(X_train).float())\n",
    "    labels = Variable(torch.from_numpy(y_train).float())\n",
    "\n",
    "    output = rnn(inputs) \n",
    "    \n",
    "    loss = criterion(output.view(-1), labels)\n",
    "    print(\"Epoch \", epoch, \"MSE: \", loss.item())\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference:https://github.com/thundercomb/pytorch-stock-predictor-rnn/blob/master/pytorch-stock-predictor-lstm.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
